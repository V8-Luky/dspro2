{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Net - Repurposing/Finetuning\n",
    "## Introduction\n",
    "\n",
    "This notebook is an attempt to repurpose and finetune an EfficientNet model to the task of American Sign Language detection for the DSPRO2 project at HSLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this section all the necessary libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiohttp==3.11.16 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (3.11.16)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: asttokens==3.0.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: attrs==25.3.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (25.3.0)\n",
      "Requirement already satisfied: certifi==2025.1.31 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.4.1)\n",
      "Requirement already satisfied: click==8.1.8 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (8.1.8)\n",
      "Requirement already satisfied: colorama==0.4.6 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.2.2)\n",
      "Requirement already satisfied: debugpy==1.8.13 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (1.8.13)\n",
      "Requirement already satisfied: decorator==5.2.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (5.2.1)\n",
      "Requirement already satisfied: docker-pycreds==0.4.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (0.4.0)\n",
      "Requirement already satisfied: executing==2.2.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (2.2.0)\n",
      "Requirement already satisfied: fastjsonschema==2.21.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (2.21.1)\n",
      "Requirement already satisfied: filelock==3.18.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (3.18.0)\n",
      "Requirement already satisfied: frozenlist==1.5.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (1.5.0)\n",
      "Requirement already satisfied: fsspec==2025.3.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (2025.3.2)\n",
      "Requirement already satisfied: gitdb==4.0.12 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (4.0.12)\n",
      "Requirement already satisfied: GitPython==3.1.44 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (3.1.44)\n",
      "Requirement already satisfied: idna==3.10 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (6.29.5)\n",
      "Requirement already satisfied: ipython==9.1.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (9.1.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2024.10.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (2024.10.1)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (5.7.2)\n",
      "Requirement already satisfied: kagglehub==0.3.11 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (0.3.11)\n",
      "Requirement already satisfied: lightning==2.5.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (2.5.1)\n",
      "Requirement already satisfied: lightning-utilities==0.14.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (0.14.3)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (0.1.7)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.3.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (6.3.2)\n",
      "Requirement already satisfied: nbformat==5.10.4 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (3.4.2)\n",
      "Requirement already satisfied: numpy==2.2.4 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (2.2.4)\n",
      "Requirement already satisfied: packaging==24.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (24.2)\n",
      "Requirement already satisfied: parso==0.8.4 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (0.8.4)\n",
      "Requirement already satisfied: pillow==11.1.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (11.1.0)\n",
      "Requirement already satisfied: platformdirs==4.3.7 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (4.3.7)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (3.0.50)\n",
      "Requirement already satisfied: propcache==0.3.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (0.3.1)\n",
      "Requirement already satisfied: protobuf==5.29.4 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (5.29.4)\n",
      "Requirement already satisfied: psutil==7.0.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (7.0.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (0.2.3)\n",
      "Requirement already satisfied: pydantic==2.11.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (2.11.3)\n",
      "Requirement already satisfied: pydantic_core==2.33.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (2.33.1)\n",
      "Requirement already satisfied: Pygments==2.19.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (2.19.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytorch-lightning==2.5.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (2.5.1)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.4.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (26.4.0)\n",
      "Requirement already satisfied: referencing==0.36.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (0.36.2)\n",
      "Requirement already satisfied: requests==2.32.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (2.32.3)\n",
      "Requirement already satisfied: rpds-py==0.24.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (0.24.0)\n",
      "Requirement already satisfied: sentry-sdk==2.25.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (2.25.1)\n",
      "Requirement already satisfied: setproctitle==1.3.5 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (1.3.5)\n",
      "Requirement already satisfied: setuptools==78.1.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (78.1.0)\n",
      "Requirement already satisfied: six==1.17.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (1.17.0)\n",
      "Requirement already satisfied: smmap==5.0.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (5.0.2)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (1.13.1)\n",
      "Requirement already satisfied: torch==2.6.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchmetrics==1.7.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (1.7.1)\n",
      "Requirement already satisfied: torchvision==0.21.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (0.21.0+cu124)\n",
      "Requirement already satisfied: tornado==6.4.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 74)) (5.14.3)\n",
      "Requirement already satisfied: typing-inspection==0.4.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 75)) (0.4.0)\n",
      "Requirement already satisfied: typing_extensions==4.13.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 76)) (4.13.1)\n",
      "Requirement already satisfied: urllib3==2.3.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 77)) (2.3.0)\n",
      "Requirement already satisfied: wandb==0.19.9 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 78)) (0.19.9)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 79)) (0.2.13)\n",
      "Requirement already satisfied: yarl==1.19.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 80)) (1.19.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython==9.1.0->-r requirements.txt (line 24)) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->-r requirements.txt (line 69)) (3.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython==9.1.0->-r requirements.txt (line 24)) (0.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as visionmodels\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import lightning as L\n",
    "\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "import nbformat\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "import os\n",
    "\n",
    "# Our own modules\n",
    "import models.sweep_helper as sweep_helper\n",
    "\n",
    "from datapipeline.asl_image_data_module import ASLImageDataModule\n",
    "from models.asl_model import ASLModel\n",
    "from models.training import sweep, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"./dspro2/efficientnet.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "No general data preprocessing is necessary, however there will be random transforms applied to the images during training. The images are resized to 224x224 pixels, which is the input size of the EfficientNet model. The images are also normalized using the mean and standard deviation of the ImageNet dataset, which is the dataset on which the EfficientNet model was pretrained.\n",
    "\n",
    "The following cells will show the loading of the dataset and the preparation of the mentioned transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/exchange/dspro2/silent-speech/ASL_Pictures_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "img_size = 224\n",
    "\n",
    "# See https://pytorch.org/vision/master/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py\n",
    "# for more examples of transforms\n",
    "\n",
    "# Open Idea: Grayscale for anti bias\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.3, hue=0.3), # Idea: ColorJitter for anti bias\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet stats\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ASLImageDataModule(path=PATH, transforms=data_transforms, val_split_folder=\"Validation\", batch_size=32, num_workers=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLEfficientNetRepurpose(nn.Module):\n",
    "    def __init__(self, efficientnet_model: visionmodels.efficientnet.EfficientNet, dropout: float = 0.2, num_classes: int = NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.model = efficientnet_model\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.model.classifier[1].in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLEfficientNetFinetune(ASLEfficientNetRepurpose):\n",
    "    def __init__(self, efficientnet_model: visionmodels.efficientnet.EfficientNet, dropout: float = 0.2, unfreeze_features: int = 1, num_classes: int = NUM_CLASSES):\n",
    "        super().__init__(efficientnet_model, dropout, num_classes)\n",
    "\n",
    "        assert unfreeze_features > 0, \"unfreeze_features must be greater than 0\"\n",
    "        unfreeze_features = min(unfreeze_features, len(self.model.features))\n",
    "\n",
    "        self.model.features[-unfreeze_features:].requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNE_TYPE = \"tune_type\"\n",
    "EFFICIENTNET_MODEL = \"efficientnet_model\"\n",
    "DROPOUT = \"dropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_efficientnet_model(model_type: str):\n",
    "    if model_type == \"b0\":\n",
    "        efficientnet_model = visionmodels.efficientnet_b0(weights=visionmodels.EfficientNet_B0_Weights.DEFAULT)\n",
    "    elif model_type == \"b1\":\n",
    "        efficientnet_model = visionmodels.efficientnet_b1(weights=visionmodels.EfficientNet_B1_Weights.DEFAULT)\n",
    "    elif model_type == \"b2\":\n",
    "        efficientnet_model = visionmodels.efficientnet_b2(weights=visionmodels.EfficientNet_B2_Weights.DEFAULT)\n",
    "    elif model_type == \"b3\":\n",
    "        efficientnet_model = visionmodels.efficientnet_b3(weights=visionmodels.EfficientNet_B3_Weights.DEFAULT)\n",
    "    elif model_type == \"b4\":\n",
    "        efficientnet_model = visionmodels.efficientnet_b4(weights=visionmodels.EfficientNet_B4_Weights.DEFAULT)\n",
    "    elif model_type == \"b5\":\n",
    "        efficientnet_model = visionmodels.efficientnet_b5(weights=visionmodels.EfficientNet_B5_Weights.DEFAULT)\n",
    "    elif model_type == \"b6\":\n",
    "        efficientnet_model = visionmodels.efficientnet_b6(weights=visionmodels.EfficientNet_B6_Weights.DEFAULT)\n",
    "    elif model_type == \"b7\":\n",
    "        efficientnet_model = visionmodels.efficientnet_b7(weights=visionmodels.EfficientNet_B7_Weights.DEFAULT)\n",
    "\n",
    "    return efficientnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNFREEZE_FEATURES = \"unfreeze_features\"\n",
    "\n",
    "def get_asl_efficientnet_model(type: str, efficientnet_model: visionmodels.efficientnet.EfficientNet, dropout: float, unfreeze_features: int = 1) -> nn.Module:\n",
    "    if type == \"repurpose\":\n",
    "        model = ASLEfficientNetRepurpose(efficientnet_model, dropout=dropout)\n",
    "    elif type == \"finetune\":\n",
    "        model = ASLEfficientNetFinetune(efficientnet_model, dropout=dropout, unfreeze_features=unfreeze_features)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model type: {type}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_efficientnet_model_from_config(config: dict) -> nn.Module:\n",
    "    efficientnet_model = get_pretrained_efficientnet_model(config[EFFICIENTNET_MODEL])\n",
    "    model = get_asl_efficientnet_model(config[TUNE_TYPE], efficientnet_model, config[DROPOUT], config[UNFREEZE_FEATURES])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 0\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def train_efficient_net():\n",
    "    train_model(\"efficientnet\", get_efficientnet_model_from_config, datamodule, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"EfficientNet-B0-B2-Repurpose\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": f\"{ASLModel.VALID_ACCURACY}\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 5\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        TUNE_TYPE: {\n",
    "            \"values\": [\"repurpose\"]\n",
    "        },\n",
    "        EFFICIENTNET_MODEL: {\n",
    "            \"values\": [\"b0\", \"b1\", \"b2\"]\n",
    "        },\n",
    "        UNFREEZE_FEATURES: {\n",
    "            \"min\": 0,\n",
    "            \"max\": 8\n",
    "        },\n",
    "        DROPOUT: {\n",
    "            \"min\": 0.1,\n",
    "            \"max\": 0.5\n",
    "        },\n",
    "        sweep_helper.OPTIMIZER: {\n",
    "            \"parameters\": {\n",
    "                sweep_helper.TYPE: {\n",
    "                    \"values\": [sweep_helper.OptimizerType.ADAM, sweep_helper.OptimizerType.ADAMW, sweep_helper.OptimizerType.RMSPROP]\n",
    "                },\n",
    "                sweep_helper.LEARNING_RATE: {\n",
    "                    \"min\": 1e-5,\n",
    "                    \"max\": 1e-2,\n",
    "                    \"distribution\": \"log_uniform_values\"\n",
    "                },\n",
    "                sweep_helper.WEIGHT_DECAY: {\n",
    "                    \"min\": 0,\n",
    "                    \"max\": 1e-3,\n",
    "                },\n",
    "                sweep_helper.MOMENTUM: {\n",
    "                    \"min\": 0.8,\n",
    "                    \"max\": 0.99\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        sweep_helper.LEARNING_RATE_SCHEDULER: {\n",
    "            \"parameters\": {\n",
    "                sweep_helper.TYPE: {\n",
    "                    \"values\": [sweep_helper.LearningRateSchedulerType.NONE, sweep_helper.LearningRateSchedulerType.STEP, sweep_helper.LearningRateSchedulerType.EXPONENTIAL, sweep_helper.LearningRateSchedulerType.CONSTANT]\n",
    "                },\n",
    "                sweep_helper.STEP_SIZE: {\n",
    "                    \"min\": 1,\n",
    "                    \"max\": 10\n",
    "                },\n",
    "                sweep_helper.GAMMA: {\n",
    "                    \"min\": 0.1,\n",
    "                    \"max\": 0.9\n",
    "                },\n",
    "                sweep_helper.FACTOR: {\n",
    "                    \"min\": 0.1,\n",
    "                    \"max\": 0.5,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: Invalid sweep config: Invalid search type bayesian, must be one of [\"grid\", \"random\", \"bayes\"] (<Response [400]>)\n"
     ]
    },
    {
     "ename": "UsageError",
     "evalue": "Invalid sweep config: Invalid search type bayesian, must be one of [\"grid\", \"random\", \"bayes\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/sdk/lib/retry.py:134\u001b[39m, in \u001b[36mRetry.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# Only print resolved attempts once every minute\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/sdk/internal/internal_api.py:402\u001b[39m, in \u001b[36mApi.execute\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py:52\u001b[39m, in \u001b[36mClient.execute\u001b[39m\u001b[34m(self, document, *args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mself\u001b[39m.validate(document)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.errors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py:60\u001b[39m, in \u001b[36mClient._get_result\u001b[39m\u001b[34m(self, document, *args, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.retries:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m last_exception = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/sdk/lib/gql_request.py:59\u001b[39m, in \u001b[36mGraphQLSession.execute\u001b[39m\u001b[34m(self, document, variable_values, timeout)\u001b[39m\n\u001b[32m     58\u001b[39m request = \u001b[38;5;28mself\u001b[39m.session.post(\u001b[38;5;28mself\u001b[39m.url, **post_args)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m result = request.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://api.wandb.ai/graphql",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mUsageError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_procedure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_efficient_net\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dspro2/models/training.py:103\u001b[39m, in \u001b[36msweep\u001b[39m\u001b[34m(sweep_config, count, training_procedure)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m run_id\n\u001b[32m    101\u001b[39m run_id = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m sweep_id = \u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43msweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROJECT_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mENTITY_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m wandb.agent(sweep_id=sweep_id, function=training_procedure, count=count)\n\u001b[32m    105\u001b[39m wandb.teardown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/sdk/wandb_sweep.py:86\u001b[39m, in \u001b[36msweep\u001b[39m\u001b[34m(sweep, entity, project, prior_runs)\u001b[39m\n\u001b[32m     84\u001b[39m     wandb_login._login(_silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     85\u001b[39m api = InternalApi()\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m sweep_id, warnings = \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_runs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprior_runs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m handle_sweep_config_violations(warnings)\n\u001b[32m     88\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreate sweep with ID:\u001b[39m\u001b[33m\"\u001b[39m, sweep_id)  \u001b[38;5;66;03m# noqa: T201\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/apis/internal.py:137\u001b[39m, in \u001b[36mApi.upsert_sweep\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupsert_sweep\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/apis/normalize.py:65\u001b[39m, in \u001b[36mnormalize_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CommError(message, err.last_exception).with_traceback(\n\u001b[32m     62\u001b[39m             sys.exc_info()[\u001b[32m2\u001b[39m]\n\u001b[32m     63\u001b[39m         )\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# gql raises server errors with dict's as strings...\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(err.args) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/apis/normalize.py:25\u001b[39m, in \u001b[36mnormalize_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mWhoa, you found a bug.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     28\u001b[39m     errors = parse_backend_error_messages(error.response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/sdk/internal/internal_api.py:3401\u001b[39m, in \u001b[36mApi.upsert_sweep\u001b[39m\u001b[34m(self, config, controller, launch_scheduler, scheduler, obj_id, project, entity, state, prior_runs, template_variable_values)\u001b[39m\n\u001b[32m   3395\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.gql(\n\u001b[32m   3396\u001b[39m         mutation,\n\u001b[32m   3397\u001b[39m         variable_values=variables,\n\u001b[32m   3398\u001b[39m         check_retry_fn=util.no_retry_4xx,\n\u001b[32m   3399\u001b[39m     )\n\u001b[32m   3400\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UsageError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   3402\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3403\u001b[39m     \u001b[38;5;66;03m# graphql schema exception is generic\u001b[39;00m\n\u001b[32m   3404\u001b[39m     err = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/sdk/internal/internal_api.py:3395\u001b[39m, in \u001b[36mApi.upsert_sweep\u001b[39m\u001b[34m(self, config, controller, launch_scheduler, scheduler, obj_id, project, entity, state, prior_runs, template_variable_values)\u001b[39m\n\u001b[32m   3392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[32m   3393\u001b[39m         variables[\u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m] = state\n\u001b[32m-> \u001b[39m\u001b[32m3395\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmutation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_retry_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_retry_4xx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3399\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3400\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UsageError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/sdk/internal/internal_api.py:374\u001b[39m, in \u001b[36mApi.gql\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgql\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_gql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_cancel_event\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcancel_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/sdk/lib/retry.py:150\u001b[39m, in \u001b[36mRetry.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retryable_exceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# if the secondary check fails, re-raise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     retry_timedelta_triggered = \u001b[43mcheck_retry_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m retry_timedelta_triggered:\n\u001b[32m    152\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/wandb/util.py:855\u001b[39m, in \u001b[36mno_retry_4xx\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    853\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    854\u001b[39m body = json.loads(e.response.content)\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UsageError(body[\u001b[33m\"\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mUsageError\u001b[39m: Invalid sweep config: Invalid search type bayesian, must be one of [\"grid\", \"random\", \"bayes\"]"
     ]
    }
   ],
   "source": [
    "sweep(sweep_config=sweep_config, count=20, training_procedure=train_efficient_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_sweep_config_b0 = {\n",
    "    \"name\": \"EfficientNet-B0-Finetune\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": f\"{ASLModel.VALID_ACCURACY}\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 5\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        TUNE_TYPE: {\n",
    "            \"value\": \"finetune\"\n",
    "        },\n",
    "        EFFICIENTNET_MODEL: {\n",
    "            \"value\": \"b0\"\n",
    "        },\n",
    "        UNFREEZE_FEATURES: {\n",
    "            \"min\": 1,\n",
    "            \"max\": 9\n",
    "        },\n",
    "        DROPOUT: {\n",
    "            \"min\": 0.1,\n",
    "            \"max\": 0.5\n",
    "        },\n",
    "        sweep_helper.OPTIMIZER: {\n",
    "            \"parameters\": {\n",
    "                sweep_helper.TYPE: {\n",
    "                    \"value\": sweep_helper.OptimizerType.RMSPROP\n",
    "                },\n",
    "                sweep_helper.LEARNING_RATE: {\n",
    "                    \"min\": 1e-5,\n",
    "                    \"max\": 1e-2,\n",
    "                    \"distribution\": \"log_uniform_values\"\n",
    "                },\n",
    "                sweep_helper.WEIGHT_DECAY: {\n",
    "                    \"min\": 0,\n",
    "                    \"max\": 1e-3,\n",
    "                },\n",
    "                sweep_helper.MOMENTUM: {\n",
    "                    \"min\": 0.8,\n",
    "                    \"max\": 0.99\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        sweep_helper.LEARNING_RATE_SCHEDULER: {\n",
    "            \"parameters\": {\n",
    "                sweep_helper.TYPE: {\n",
    "                    \"values\": [sweep_helper.LearningRateSchedulerType.NONE, sweep_helper.LearningRateSchedulerType.STEP, sweep_helper.LearningRateSchedulerType.EXPONENTIAL]\n",
    "                },\n",
    "                sweep_helper.STEP_SIZE: {\n",
    "                    \"min\": 1,\n",
    "                    \"max\": 10\n",
    "                },\n",
    "                sweep_helper.GAMMA: {\n",
    "                    \"min\": 0.1,\n",
    "                    \"max\": 0.9\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: da3s4woi\n",
      "Sweep URL: https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/da3s4woi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5ya04w7r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4882254824597369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tefficientnet_model: b0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'gamma': 0.12207377267316807, 'step_size': 8, 'type': 'exponential'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 0.00014626705462299463, 'momentum': 0.9600000119859484, 'type': 'rmsprop', 'weight_decay': 0.0003786203337267541}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttune_type: finetune\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_features: 2\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mv8-luky\u001b[0m (\u001b[33mdspro2-silent-speech\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/dspro2/wandb/run-20250410_222034-5ya04w7r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/5ya04w7r' target=\"_blank\">efficientnet-1</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/da3s4woi' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/da3s4woi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/da3s4woi' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/da3s4woi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/5ya04w7r' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/5ya04w7r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A16') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/opt/conda/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type                    | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | model          | ASLEfficientNetFinetune | 4.0 M  | train\n",
      "1 | criterion      | CrossEntropyLoss        | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy      | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy      | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy      | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "2.9 M     Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.174    Total estimated model params size (MB)\n",
      "342       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2568c561c6294e66a89ede3087a2853f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5bef5e27274170bfde6a60aa5de35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep(sweep_config=finetune_sweep_config_b0, count=30, training_procedure=train_efficient_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_sweep_config_b1 = {\n",
    "    \"name\": \"EfficientNet-B1-Finetune\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": f\"{ASLModel.VALID_ACCURACY}\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 5\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        TUNE_TYPE: {\n",
    "            \"value\": \"finetune\"\n",
    "        },\n",
    "        EFFICIENTNET_MODEL: {\n",
    "            \"value\": \"b0\"\n",
    "        },\n",
    "        UNFREEZE_FEATURES: {\n",
    "            \"min\": 1,\n",
    "            \"max\": 9\n",
    "        },\n",
    "        DROPOUT: {\n",
    "            \"min\": 0.1,\n",
    "            \"max\": 0.5\n",
    "        },\n",
    "        sweep_helper.OPTIMIZER: {\n",
    "            \"parameters\": {\n",
    "                sweep_helper.TYPE: {\n",
    "                    \"value\": sweep_helper.OptimizerType.RMSPROP\n",
    "                },\n",
    "                sweep_helper.LEARNING_RATE: {\n",
    "                    \"min\": 1e-5,\n",
    "                    \"max\": 1e-2,\n",
    "                    \"distribution\": \"log_uniform_values\"\n",
    "                },\n",
    "                sweep_helper.WEIGHT_DECAY: {\n",
    "                    \"min\": 0,\n",
    "                    \"max\": 1e-3,\n",
    "                },\n",
    "                sweep_helper.MOMENTUM: {\n",
    "                    \"min\": 0.8,\n",
    "                    \"max\": 0.99\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        sweep_helper.LEARNING_RATE_SCHEDULER: {\n",
    "            \"parameters\": {\n",
    "                sweep_helper.TYPE: {\n",
    "                    \"values\": [sweep_helper.LearningRateSchedulerType.NONE, sweep_helper.LearningRateSchedulerType.STEP, sweep_helper.LearningRateSchedulerType.EXPONENTIAL]\n",
    "                },\n",
    "                sweep_helper.STEP_SIZE: {\n",
    "                    \"min\": 1,\n",
    "                    \"max\": 10\n",
    "                },\n",
    "                sweep_helper.GAMMA: {\n",
    "                    \"min\": 0.1,\n",
    "                    \"max\": 0.9\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep(sweep_config=finetune_sweep_config_b1, count=30, training_procedure=train_efficient_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
