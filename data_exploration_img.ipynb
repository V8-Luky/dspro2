{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fba083-ae77-4963-8cab-3432ce9cbd7a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ab588d-ef5f-43d5-abf0-85eaa2d5f026",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipympl in /opt/conda/lib/python3.12/site-packages (0.9.6)\n",
      "Requirement already satisfied: ipython<9 in /opt/conda/lib/python3.12/site-packages (from ipympl) (8.32.0)\n",
      "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /opt/conda/lib/python3.12/site-packages (from ipympl) (8.1.5)\n",
      "Requirement already satisfied: matplotlib<4,>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from ipympl) (3.10.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from ipympl) (2.1.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (from ipympl) (11.1.0)\n",
      "Requirement already satisfied: traitlets<6 in /opt/conda/lib/python3.12/site-packages (from ipympl) (5.14.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython<9->ipympl) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython<9->ipympl) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.12/site-packages (from ipython<9->ipympl) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython<9->ipympl) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython<9->ipympl) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython<9->ipympl) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython<9->ipympl) (0.6.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/conda/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in /opt/conda/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib<4,>=3.5.0->ipympl) (2.9.0.post0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython<9->ipympl) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython<9->ipympl) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython<9->ipympl) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython<9->ipympl) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting wandb\n",
      "  Using cached wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.28.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (6.1.1)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-2.26.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Using cached setproctitle-1.3.5-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Using cached wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached sentry_sdk-2.26.1-py2.py3-none-any.whl (340 kB)\n",
      "Using cached setproctitle-1.3.5-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Installing collected packages: setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 sentry-sdk-2.26.1 setproctitle-1.3.5 wandb-0.19.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipympl\n",
    "%pip install python-dotenv\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2698210-718a-4ea6-b9fe-90bdadcbed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9306f-3779-401e-a7c9-439b65be8692",
   "metadata": {},
   "source": [
    "## CNN images model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e29c204c-2518-4f09-a5ac-9f512dedb839",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\"\"\"\n",
    "class AslCNN_img(nn.Module):\n",
    "    def __init__(self, num_classes, kernel_size=3, padding=1, channels=[16,32,64]):\n",
    "        super(AslCNN_img, self).__init__()\n",
    "\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(3, channels[0], kernel_size, padding)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "    \n",
    "        self.conv2 = nn.Conv2d(channels[0], channels[1], kernel_size, padding)\n",
    "        self.conv3 = nn.Conv2d(channels[1], channels[2], kernel_size, padding)\n",
    "\n",
    "        # For 400x400 images size and 3 pooling layers\n",
    "        final_spatial_dim = 400 // (2**3) \n",
    "        flattened_size = channels[2] * final_spatial_dim * final_spatial_dim\n",
    "    \n",
    "        self.fc1 = nn.Linear(flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes) # Number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AslCNN_img(nn.Module):\n",
    "    def __init__(self, num_classes, kernel_size=3, padding=1, channels=[16, 32, 64]):\n",
    "        super(AslCNN_img, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, channels[0], kernel_size, padding)\n",
    "        self.conv2 = nn.Conv2d(channels[0], channels[1], kernel_size, padding)\n",
    "        self.conv3 = nn.Conv2d(channels[1], channels[2], kernel_size, padding)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # On initialise fc1 à None et on le créera dans le forward\n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if self.fc1 is None:\n",
    "            # Première fois qu'on passe ici : on initialise fc1 dynamiquement\n",
    "            self.fc1 = nn.Linear(x.size(1), 128)\n",
    "            # Enregistre fc1 dans les paramètres du modèle (sinon il ne sera pas entraîné)\n",
    "            self.add_module('fc1', self.fc1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07eb5955-44e6-4d81-8e31-ee6016bbd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ASLCNN_img(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ASLCNN_img, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3), # 400 -> 200\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 200 -> 100\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 100\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 100 -> 50\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 50\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 50 -> 25\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 25 * 25, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 29)  # number of classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3e93b2-f05d-4e86-a54d-b30dcb9b439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4fd422ffb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46dbc22-1331-4c30-847f-5ccb9428fe2b",
   "metadata": {},
   "source": [
    "## Training, validation, test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1e2a99-8763-4259-9a4b-08727eb8c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# TRAIN FUNCTION\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_predictions = []\n",
    "    train_labels = []\n",
    "\n",
    "    for X_batch, y_batch in train_loader: \n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_predictions.append(predicted.cpu())\n",
    "        train_labels.append(y_batch.cpu())\n",
    "\n",
    "    epoch_avg_loss = total_loss / len(train_loader)\n",
    "    return epoch_avg_loss, train_predictions, train_labels\n",
    "\n",
    "\n",
    "# VALIDATION FUNCTION\n",
    "def validate(model, val_loader, criterion):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            outputs = model(X_val_batch)\n",
    "            loss = criterion(outputs, y_val_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == y_val_batch).sum().item()\n",
    "            total += y_val_batch.size(0)\n",
    "\n",
    "            val_predictions.append(predicted.cpu())\n",
    "            val_labels.append(y_val_batch.cpu())\n",
    "\n",
    "    val_predictions = torch.cat(val_predictions).numpy()\n",
    "    val_labels = torch.cat(val_labels).numpy()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    precision = precision_score(val_labels, val_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(val_labels, val_predictions, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(val_labels, val_predictions)\n",
    "\n",
    "    if conf_matrix.shape == (2, 2):\n",
    "        specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    else:\n",
    "        specificity = 0\n",
    "\n",
    "    sensitivity = recall\n",
    "    sk_learn_acc = accuracy_score(val_labels, val_predictions)\n",
    "\n",
    "    return avg_val_loss, val_accuracy, precision, recall, specificity, sensitivity, sk_learn_acc\n",
    "\n",
    "\n",
    "# TRAIN + VALIDATE FUNCTION\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    epoch_losses = []\n",
    "    best_val_accuracy = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_predictions = []\n",
    "    best_model_labels = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_avg_loss, train_predictions, train_labels = train(model, train_loader, criterion, optimizer)\n",
    "        epoch_losses.append(train_avg_loss)\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {train_avg_loss:.4f}\")\n",
    "\n",
    "        val_avg_loss, val_accuracy, precision, recall, specificity, sensitivity, sk_learn_acc = validate(model, val_loader, criterion)\n",
    "        print(f\"[Epoch {epoch+1}] Val Loss: {val_avg_loss:.4f} | Val Acc: {val_accuracy:.2f}% | Precision: {precision:.2f} | Recall: {recall:.2f}\")\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_predictions = train_predictions.copy()\n",
    "            best_model_labels = train_labels.copy()\n",
    "            torch.save(model.state_dict(), f'best_model_{current_time}.pth')\n",
    "\n",
    "    print(\" Training complete!\")\n",
    "    print(f\" Best model: Epoch {best_epoch} with Val Accuracy: {best_val_accuracy:.2f}%\")\n",
    "    \n",
    "    return model, best_model_predictions, best_model_labels, epoch_losses, best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a126af2a-09ec-42f1-9431-165d4aa4c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "dataset_path_img = '/exchange/dspro2/silent-speech/ASL_Pictures_Dataset'\n",
    "train_path = f'{dataset_path_img}/Train'\n",
    "validate_path = f'{dataset_path_img}/Validation'\n",
    "\n",
    "\n",
    "# Pré-traitement des images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((400, 400)),   # Resize les images\n",
    "    transforms.ToTensor(),           # Convertit en tenseur PyTorch\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalisation (valeurs entre -1 et 1)\n",
    "])\n",
    "\n",
    "# Chargement des datasets avec ImageFolder\n",
    "train_dataset = ImageFolder(root=train_path, transform=transform)\n",
    "val_dataset = ImageFolder(root=validate_path, transform=transform)\n",
    "\n",
    "# Création des DataLoaders\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e73f1c7-6b1c-4524-9779-5f595cafd5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.8157\n",
      "[Epoch 1] Val Loss: 0.0864 | Val Acc: 97.56% | Precision: 0.98 | Recall: 0.98\n",
      "[Epoch 2] Train Loss: 0.1144\n",
      "[Epoch 2] Val Loss: 0.0188 | Val Acc: 99.59% | Precision: 1.00 | Recall: 1.00\n",
      " Training complete!\n",
      " Best model: Epoch 2 with Val Accuracy: 99.59%\n"
     ]
    }
   ],
   "source": [
    "# CNN IMAGES\n",
    "\n",
    "num_classes = 29\n",
    "device = torch.device(\"cuda\")\n",
    "model = ASLCNN_img().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001) #weight_decay = regularization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Call the train_and_validate function to train and validate the model\n",
    "trained_model, best_model_predictions, best_model_labels, epoch_losses, sk_learn_acc = train_and_validate(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3ae5a-ee1a-4e70-a391-0780fc4b7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single batch from the DataLoader\n",
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "# Unpack the batch\n",
    "print(f\"Type of sample_batch: {type(sample_batch)}\")\n",
    "print(f\"Length of sample_batch: {len(sample_batch)}\")\n",
    "\n",
    "# Print what's inside\n",
    "for i, item in enumerate(sample_batch):\n",
    "    print(f\"Item {i}: type = {type(item)}, shape = {item.shape if hasattr(item, 'shape') else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d4533-14cc-4325-8f5e-101af410f989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a54e03-9fd0-4966-922a-8564e977e75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
