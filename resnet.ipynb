{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Res Net - Repurposing/Finetuning\n",
    "## Introduction\n",
    "\n",
    "This notebook is an attempt to repurpose and finetune an ResNet model to the task of American Sign Language detection for the DSPRO2 project at HSLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this section all the necessary libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as visionmodels\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import lightning as L\n",
    "\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "import nbformat\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "import os\n",
    "\n",
    "# Our own modules\n",
    "import models.sweep_helper as sweep_helper\n",
    "\n",
    "from datapipeline.asl_image_data_module import ASLImageDataModule\n",
    "from datapipeline.asl_kaggle_image_data_module import ASLKaggleImageDataModule\n",
    "from models.asl_model import ASLModel\n",
    "from models.training import sweep, train_model, PROJECT_NAME, ENTITY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"./dspro2/efficientnet.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "No general data preprocessing is necessary, however there will be random transforms applied to the images during training. The images are resized to 224x224 pixels, which is the input size of the EfficientNet model. The images are also normalized using the mean and standard deviation of the ImageNet dataset, which is the dataset on which the EfficientNet model was pretrained.\n",
    "\n",
    "The following cells will show the loading of the dataset and the preparation of the mentioned transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/exchange/dspro2/silent-speech/ASL_Pictures_Dataset\"\n",
    "PATH = r\"C:\\Temp\\silent-speech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule = ASLImageDataModule(path=PATH, val_split_folder=\"Validation\", batch_size=32, num_workers=128)\n",
    "datamodule = ASLKaggleImageDataModule(path=PATH, batch_size=32, num_workers=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLResNet34(nn.Module):\n",
    "    def __init__(self, resnet_model: visionmodels.resnet.ResNet, dropout: float = 0.2, unfreeze_layers: int = 0, num_classes: int = NUM_CLASSES):\n",
    "        super().__init__()\n",
    "\n",
    "        resnet_num_layers = 4\n",
    "        self.model = resnet_model\n",
    "        self.model.requires_grad_(False)\n",
    "\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        )\n",
    "\n",
    "        unfreeze_layers = min(unfreeze_layers, resnet_num_layers)\n",
    "\n",
    "        for layer_num in range(resnet_num_layers, resnet_num_layers - unfreeze_layers, -1):\n",
    "            self.model.get_submodule(f\"layer{layer_num}\").requires_grad_(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = \"dropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_resnet_model():\n",
    "    resnet_model = visionmodels.resnet34(weights=visionmodels.ResNet34_Weights.DEFAULT)\n",
    "    return resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNFREEZE_LAYERS = \"unfreeze_layers\"\n",
    "\n",
    "\n",
    "def get_asl_resnet_model(resnet_model: visionmodels.resnet.ResNet, dropout: float, unfreeze_layers: int = 0) -> nn.Module:\n",
    "    model = ASLResNet34(resnet_model, dropout=dropout, unfreeze_layers=unfreeze_layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_model_from_config(config: dict) -> nn.Module:\n",
    "    resnet_model = get_pretrained_resnet_model()\n",
    "    model = get_asl_resnet_model(resnet_model, config[DROPOUT], config[UNFREEZE_LAYERS])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 0\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def train_resnet():\n",
    "    train_model(\"resnet\", get_resnet_model_from_config, datamodule, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"ResNet34\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": f\"{ASLModel.VALID_ACCURACY}\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 5\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        UNFREEZE_LAYERS: {\n",
    "            \"min\": 0,\n",
    "            \"max\": 4\n",
    "        },\n",
    "        DROPOUT: {\n",
    "            \"min\": 0.1,\n",
    "            \"max\": 0.5\n",
    "        },\n",
    "        sweep_helper.OPTIMIZER: {\n",
    "            \"parameters\": {\n",
    "                sweep_helper.TYPE: {\n",
    "                    \"values\": [sweep_helper.OptimizerType.ADAM, sweep_helper.OptimizerType.RMSPROP]\n",
    "                },\n",
    "                sweep_helper.LEARNING_RATE: {\n",
    "                    \"min\": 1e-5,\n",
    "                    \"max\": 1e-3,\n",
    "                    \"distribution\": \"log_uniform_values\"\n",
    "                },\n",
    "                sweep_helper.WEIGHT_DECAY: {\n",
    "                    \"min\": 0,\n",
    "                    \"max\": 1e-3,\n",
    "                },\n",
    "                sweep_helper.MOMENTUM: {\n",
    "                    \"min\": 0.8,\n",
    "                    \"max\": 0.99\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        sweep_helper.LEARNING_RATE_SCHEDULER: {\n",
    "            \"parameters\": {\n",
    "                sweep_helper.TYPE: {\n",
    "                    \"values\": [sweep_helper.LearningRateSchedulerType.NONE, sweep_helper.LearningRateSchedulerType.EXPONENTIAL, sweep_helper.LearningRateSchedulerType.CONSTANT]\n",
    "                },\n",
    "                sweep_helper.STEP_SIZE: {\n",
    "                    \"min\": 1,\n",
    "                    \"max\": 10\n",
    "                },\n",
    "                sweep_helper.GAMMA: {\n",
    "                    \"min\": 0.1,\n",
    "                    \"max\": 0.9\n",
    "                },\n",
    "                sweep_helper.FACTOR: {\n",
    "                    \"min\": 0.1,\n",
    "                    \"max\": 0.5,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: sauoowd2\n",
      "Sweep URL: https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ys1puvfm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3712688204353206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.3445691610529318, 'gamma': 0.5392523577005552, 'step_size': 1, 'type': 'constant'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 0.0003908997167515904, 'momentum': 0.9438227402892524, 'type': 'rmsprop', 'weight_decay': 0.00033800645759274686}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 4\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250421_232212-ys1puvfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/ys1puvfm' target=\"_blank\">resnet-1</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/ys1puvfm' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/ys1puvfm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "9.5 K     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:58<00:00,  5.77it/s, v_num=uvfm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.891\n",
      "Metric train_accuracy improved. New best score: 0.745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [10:15<00:00,  5.05it/s, v_num=uvfm] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.202 >= min_delta = 0.0. New best score: 0.947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [10:17<00:00,  5.03it/s, v_num=uvfm] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.039 >= min_delta = 0.0. New best score: 0.929\n",
      "Metric train_accuracy improved by 0.015 >= min_delta = 0.0. New best score: 0.962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [10:12<00:00,  5.08it/s, v_num=uvfm] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.023 >= min_delta = 0.0. New best score: 0.953\n",
      "Metric train_accuracy improved by 0.004 >= min_delta = 0.0. New best score: 0.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [10:13<00:00,  5.06it/s, v_num=uvfm] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.015 >= min_delta = 0.0. New best score: 0.968\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3109/3109 [10:13<00:00,  5.07it/s, v_num=uvfm] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.968. Signaling Trainer to stop.\n",
      "Monitored metric train_accuracy did not improve in the last 5 records. Best score: 0.968. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3109/3109 [10:14<00:00,  5.06it/s, v_num=uvfm]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr-RMSprop</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████</td></tr><tr><td>lr-RMSprop-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇███▇▇▇▇▇</td></tr><tr><td>train_accuracy_step</td><td>▁▅▇▇▇█▃▅▇▆▆▇▇▆▇█▇██▇█▇▄▄▅▇▄▅▇▇▅▆▇▅▆▇▇▅██</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▂▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▇▅▂▅▁▁▁▂▁▁▁▅▂▂▂▁▃▃▃▄▄▂▅▆▂▁▅▄▁█▄▃▆▃▂▂▂▅▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃█▃▃▃▃▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>valid_accuracy_epoch</td><td>▅▅▆▇█▄▂▁▂▅</td></tr><tr><td>valid_accuracy_step</td><td>▆█▇▅█▁█▆▆█▇▇▅█▇▇████▇▇▇▁▆▆█▇█▅▇█▁▅▆▄█▇█▆</td></tr><tr><td>valid_loss_epoch</td><td>▄▄▂▂▁▅▆█▇▄</td></tr><tr><td>valid_loss_step</td><td>▂▅▃▁▁▂▃▁▂▂▂▁▁▁▂▂▂▁▁▂▃▂▁▁▂▁▄▃▃▁▇▂▃▂█▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>lr-RMSprop</td><td>0.00039</td></tr><tr><td>lr-RMSprop-momentum</td><td>0.94382</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>0.00034</td></tr><tr><td>train_accuracy_epoch</td><td>0.93771</td></tr><tr><td>train_accuracy_step</td><td>0.96875</td></tr><tr><td>train_loss_epoch</td><td>0.21377</td></tr><tr><td>train_loss_step</td><td>0.08444</td></tr><tr><td>trainer/global_step</td><td>31089</td></tr><tr><td>valid_accuracy_epoch</td><td>0.88053</td></tr><tr><td>valid_accuracy_step</td><td>1</td></tr><tr><td>valid_loss_epoch</td><td>0.42831</td></tr><tr><td>valid_loss_step</td><td>0.1516</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-1</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/ys1puvfm' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/ys1puvfm</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_232212-ys1puvfm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2b5tkcmx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3083884115237969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.47410379731693986, 'gamma': 0.8485961005825423, 'step_size': 3, 'type': 'constant'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 1.5132481142806917e-05, 'momentum': 0.9361363159719498, 'type': 'rmsprop', 'weight_decay': 0.0005822330790058964}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 3\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_010821-2b5tkcmx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2b5tkcmx' target=\"_blank\">resnet-2</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2b5tkcmx' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2b5tkcmx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.1 M    Trainable params\n",
      "231 K     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:16<00:00,  6.26it/s, v_num=kcmx]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.994\n",
      "Metric train_accuracy improved. New best score: 0.980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [10:03<00:00,  5.15it/s, v_num=kcmx] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.995\n",
      "Metric train_accuracy improved by 0.013 >= min_delta = 0.0. New best score: 0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [10:04<00:00,  5.14it/s, v_num=kcmx] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [10:09<00:00,  5.10it/s, v_num=kcmx] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [10:07<00:00,  5.11it/s, v_num=kcmx] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [10:10<00:00,  5.10it/s, v_num=kcmx] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.995. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [10:11<00:00,  5.08it/s, v_num=kcmx]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>lr-RMSprop</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████</td></tr><tr><td>lr-RMSprop-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇███▆▇</td></tr><tr><td>train_accuracy_step</td><td>▅█▅██████████▁███████▅███▅█▅███████████▁</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▄▃</td></tr><tr><td>train_loss_step</td><td>▂▁▁▁▁▁▄▁▂▂▁▁▂▁▁▁▁▁▁▅▁▁▁▂▁▁▃▄▁▁█▁▂▅▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▅▂▂▂▂▂▂▂▂▃▃▆▃▃▃██▃▃▃▃▃</td></tr><tr><td>valid_accuracy_epoch</td><td>██▁▆▆▅▅</td></tr><tr><td>valid_accuracy_step</td><td>▆█████████▆▅▆▆██████████▆██████▅▁█▆█████</td></tr><tr><td>valid_loss_epoch</td><td>▂▁█▃▃▅▅</td></tr><tr><td>valid_loss_step</td><td>▅▁▁▅▁▁▁▁▁▁▁▁▁▁▁▆▁█▁▂▁▁▁▁▅▁▁▁▂▃▁▁▁▁▁▁▁▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>lr-RMSprop</td><td>2e-05</td></tr><tr><td>lr-RMSprop-momentum</td><td>0.93614</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>0.00058</td></tr><tr><td>train_accuracy_epoch</td><td>0.99235</td></tr><tr><td>train_accuracy_step</td><td>0.9375</td></tr><tr><td>train_loss_epoch</td><td>0.03536</td></tr><tr><td>train_loss_step</td><td>0.14804</td></tr><tr><td>trainer/global_step</td><td>21762</td></tr><tr><td>valid_accuracy_epoch</td><td>0.99131</td></tr><tr><td>valid_accuracy_step</td><td>1</td></tr><tr><td>valid_loss_epoch</td><td>0.03641</td></tr><tr><td>valid_loss_step</td><td>0.00011</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-2</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2b5tkcmx' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2b5tkcmx</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_010821-2b5tkcmx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mxdyu7iu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.12279790627824257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.29535831269234913, 'gamma': 0.26073129741741663, 'step_size': 1, 'type': 'constant'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 0.00021548992220871848, 'momentum': 0.8799236995925267, 'type': 'rmsprop', 'weight_decay': 0.00035435800267666383}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 2\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_022223-mxdyu7iu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/mxdyu7iu' target=\"_blank\">resnet-3</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/mxdyu7iu' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/mxdyu7iu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "20.0 M    Trainable params\n",
      "1.3 M     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:14<00:00,  6.29it/s, v_num=u7iu]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.972\n",
      "Metric train_accuracy improved. New best score: 0.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [09:57<00:00,  5.20it/s, v_num=u7iu] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.018 >= min_delta = 0.0. New best score: 0.990\n",
      "Metric train_accuracy improved by 0.029 >= min_delta = 0.0. New best score: 0.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [10:01<00:00,  5.17it/s, v_num=u7iu] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.004 >= min_delta = 0.0. New best score: 0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [09:59<00:00,  5.18it/s, v_num=u7iu] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [09:53<00:00,  5.24it/s, v_num=u7iu] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [10:00<00:00,  5.17it/s, v_num=u7iu] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.990. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [10:03<00:00,  5.15it/s, v_num=u7iu]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>lr-RMSprop</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████</td></tr><tr><td>lr-RMSprop-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇███▅▆</td></tr><tr><td>train_accuracy_step</td><td>▁▆▅▆▆█▆▆▃▆█▆███████▆███▆██████▆▆█▅█▃██▆▆</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▄▃</td></tr><tr><td>train_loss_step</td><td>▄▂▆█▃▁▃▁▆▁▁▁▁▁▁▂▄▅▁▁▁▄▁▁▁▁▁▂▁▁▂▁▂▃▃▂▂▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃█▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅</td></tr><tr><td>valid_accuracy_epoch</td><td>▂█▇▄▅▁▅</td></tr><tr><td>valid_accuracy_step</td><td>█▇███▅█▄█▇▇▇█████▇█▅██▄███▂▂█▁▅██▇█▅▇██▇</td></tr><tr><td>valid_loss_epoch</td><td>▇▁▁▅▄█▄</td></tr><tr><td>valid_loss_step</td><td>▁▁▁▁▁█▃▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▃▁▁▁▁▁▂▂▁▁▂▂▂▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>lr-RMSprop</td><td>0.00022</td></tr><tr><td>lr-RMSprop-momentum</td><td>0.87992</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>0.00035</td></tr><tr><td>train_accuracy_epoch</td><td>0.98291</td></tr><tr><td>train_accuracy_step</td><td>0.9375</td></tr><tr><td>train_loss_epoch</td><td>0.06366</td></tr><tr><td>train_loss_step</td><td>0.13778</td></tr><tr><td>trainer/global_step</td><td>21762</td></tr><tr><td>valid_accuracy_epoch</td><td>0.98154</td></tr><tr><td>valid_accuracy_step</td><td>1</td></tr><tr><td>valid_loss_epoch</td><td>0.07001</td></tr><tr><td>valid_loss_step</td><td>0.00254</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-3</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/mxdyu7iu' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/mxdyu7iu</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_022223-mxdyu7iu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xwm0prkz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4562687185436173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.16784845390602246, 'gamma': 0.17997234064886083, 'step_size': 1, 'type': 'none'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 3.505478097530085e-05, 'momentum': 0.9515142133511116, 'type': 'rmsprop', 'weight_decay': 0.00079268486581871}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 4\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_033532-xwm0prkz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/xwm0prkz' target=\"_blank\">resnet-4</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/xwm0prkz' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/xwm0prkz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "9.5 K     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:19<00:00,  6.23it/s, v_num=prkz]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.956\n",
      "Metric train_accuracy improved. New best score: 0.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [10:04<00:00,  5.14it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.006 >= min_delta = 0.0. New best score: 0.962\n",
      "Metric train_accuracy improved by 0.049 >= min_delta = 0.0. New best score: 0.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [10:05<00:00,  5.13it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.007 >= min_delta = 0.0. New best score: 0.969\n",
      "Metric train_accuracy improved by 0.005 >= min_delta = 0.0. New best score: 0.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [10:02<00:00,  5.16it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [09:56<00:00,  5.21it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.009 >= min_delta = 0.0. New best score: 0.978\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3109/3109 [10:06<00:00,  5.13it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [10:08<00:00,  5.11it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3109/3109 [10:03<00:00,  5.15it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.003 >= min_delta = 0.0. New best score: 0.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3109/3109 [10:08<00:00,  5.11it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.005 >= min_delta = 0.0. New best score: 0.986\n",
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3109/3109 [10:06<00:00,  5.13it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 3109/3109 [10:09<00:00,  5.10it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3109/3109 [10:18<00:00,  5.03it/s, v_num=prkz] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.986. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3109/3109 [10:20<00:00,  5.01it/s, v_num=prkz]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>lr-RMSprop</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇▇███████████</td></tr><tr><td>train_accuracy_step</td><td>▅▁▅▆██▆█▅██████████▅████▆█▆▆▆▆████▆██▆▆█</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▃█▃▃▂▁▁▁▂▁▁▂▁▃▂▁▃▆▁▄▃▄▆▁▁▅▃▁▁▂▁▄▁▁▁▅▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▆▃▇▃▃▃▃▃▃█▃▃██▃▃</td></tr><tr><td>valid_accuracy_epoch</td><td>▃▄▅▅▇▆▆▇█▁█▄▇▇</td></tr><tr><td>valid_accuracy_step</td><td>████████████████████████▁████████▇██▅███</td></tr><tr><td>valid_loss_epoch</td><td>▅▅▄▄▃▃▃▂▁█▁▅▂▃</td></tr><tr><td>valid_loss_step</td><td>▃▂▅▃█▃▂▂▂▁▁▁▂▁▁▁▁▄▃▁▂▂▁▁▆▂▁▆▁▂▂▁▁▁▁▁▁▁▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>lr-RMSprop</td><td>4e-05</td></tr><tr><td>lr-RMSprop-momentum</td><td>0.95151</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>0.00079</td></tr><tr><td>train_accuracy_epoch</td><td>0.98694</td></tr><tr><td>train_accuracy_step</td><td>1</td></tr><tr><td>train_loss_epoch</td><td>0.05844</td></tr><tr><td>train_loss_step</td><td>0.02875</td></tr><tr><td>trainer/global_step</td><td>43525</td></tr><tr><td>valid_accuracy_epoch</td><td>0.97825</td></tr><tr><td>valid_accuracy_step</td><td>1</td></tr><tr><td>valid_loss_epoch</td><td>0.09146</td></tr><tr><td>valid_loss_step</td><td>0.03565</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-4</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/xwm0prkz' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/xwm0prkz</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_033532-xwm0prkz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o8o5wkae with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2112319526174473\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.2362694259965708, 'gamma': 0.19969300372467844, 'step_size': 3, 'type': 'none'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 0.0007571464321036416, 'momentum': 0.8371226988533499, 'type': 'adam', 'weight_decay': 0.0006234845246880222}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 3\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_060033-o8o5wkae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/o8o5wkae' target=\"_blank\">resnet-5</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/o8o5wkae' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/o8o5wkae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.1 M    Trainable params\n",
      "231 K     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:07<00:00,  6.38it/s, v_num=wkae]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.949\n",
      "Metric train_accuracy improved. New best score: 0.953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [10:00<00:00,  5.17it/s, v_num=wkae] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.037 >= min_delta = 0.0. New best score: 0.985\n",
      "Metric train_accuracy improved by 0.027 >= min_delta = 0.0. New best score: 0.980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [09:56<00:00,  5.21it/s, v_num=wkae] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.003 >= min_delta = 0.0. New best score: 0.988\n",
      "Metric train_accuracy improved by 0.006 >= min_delta = 0.0. New best score: 0.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [09:57<00:00,  5.20it/s, v_num=wkae] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [09:57<00:00,  5.21it/s, v_num=wkae] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3109/3109 [09:59<00:00,  5.18it/s, v_num=wkae] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [10:03<00:00,  5.15it/s, v_num=wkae] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3109/3109 [09:56<00:00,  5.21it/s, v_num=wkae] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.988. Signaling Trainer to stop.\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3109/3109 [09:59<00:00,  5.19it/s, v_num=wkae]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇██████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-Adam-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-Adam-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▆▇▇████</td></tr><tr><td>train_accuracy_step</td><td>▁▆▁▆▆█▃▆████▆▆█████▃█▆███▆▆██▆▆▆█▆███▆██</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▆▃▅▂▃▁▃▂▅▄▂▂▁▃▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▂▁▁▃▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▂▂▁▁▁▁▁▁▁▁▁▁▄▂▂▂▂▂▃▃▃▃█▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅</td></tr><tr><td>valid_accuracy_epoch</td><td>▁▇█▄▅▇██</td></tr><tr><td>valid_accuracy_step</td><td>██▁▅█▁▅▁███▅▅██▅██████▅█▅██▅▅████▅▅█▅▅██</td></tr><tr><td>valid_loss_epoch</td><td>█▂▁▄▄▂▁▁</td></tr><tr><td>valid_loss_step</td><td>▁▇▃▁▃▂▂▄▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁█▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>7</td></tr><tr><td>lr-Adam</td><td>0.00076</td></tr><tr><td>lr-Adam-momentum</td><td>0.9</td></tr><tr><td>lr-Adam-weight_decay</td><td>0.00062</td></tr><tr><td>train_accuracy_epoch</td><td>0.98962</td></tr><tr><td>train_accuracy_step</td><td>1</td></tr><tr><td>train_loss_epoch</td><td>0.04582</td></tr><tr><td>train_loss_step</td><td>0.00922</td></tr><tr><td>trainer/global_step</td><td>24871</td></tr><tr><td>valid_accuracy_epoch</td><td>0.98748</td></tr><tr><td>valid_accuracy_step</td><td>1</td></tr><tr><td>valid_loss_epoch</td><td>0.04448</td></tr><tr><td>valid_loss_step</td><td>0.00717</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-5</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/o8o5wkae' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/o8o5wkae</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_060033-o8o5wkae\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qc0r54yc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.12681328017785762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.14688485169375998, 'gamma': 0.795968337303068, 'step_size': 5, 'type': 'constant'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 0.0003062556947386585, 'momentum': 0.9807497041239558, 'type': 'rmsprop', 'weight_decay': 0.00030408219450790155}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 4\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_072333-qc0r54yc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/qc0r54yc' target=\"_blank\">resnet-6</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/qc0r54yc' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/qc0r54yc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "9.5 K     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:17<00:00,  6.25it/s, v_num=54yc]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.890\n",
      "Metric train_accuracy improved. New best score: 0.866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [10:05<00:00,  5.13it/s, v_num=54yc] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.058 >= min_delta = 0.0. New best score: 0.949\n",
      "Metric train_accuracy improved by 0.093 >= min_delta = 0.0. New best score: 0.959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [10:09<00:00,  5.10it/s, v_num=54yc] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.009 >= min_delta = 0.0. New best score: 0.968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [10:10<00:00,  5.09it/s, v_num=54yc] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.010 >= min_delta = 0.0. New best score: 0.958\n",
      "Metric train_accuracy improved by 0.003 >= min_delta = 0.0. New best score: 0.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [10:12<00:00,  5.07it/s, v_num=54yc] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.003 >= min_delta = 0.0. New best score: 0.973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3109/3109 [10:07<00:00,  5.12it/s, v_num=54yc] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.958. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3109/3109 [10:08<00:00,  5.11it/s, v_num=54yc]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>lr-RMSprop</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████</td></tr><tr><td>lr-RMSprop-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇███▃▄▄▄</td></tr><tr><td>train_accuracy_step</td><td>▅▁▇▇▆██▇▇█▇▇▆▇████▇▅▅▅▇▅▄▅▃▆▇▇▅▅▂▅▇▅▇▆▆▆</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▇▅▅▅</td></tr><tr><td>train_loss_step</td><td>▇▄▃▆▂▂▂▂▄▃▃▃▂▁▁▁▂▁▁▁▁▄▅▄▄▂▃▆▅█▄▅▄▂▅▅▆▆▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▃▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>valid_accuracy_epoch</td><td>▅█▇██▂▂▁▄</td></tr><tr><td>valid_accuracy_step</td><td>▇▇█▆▇█▇██▇██▅█▇██▆███▆██▁▆▇██▇█▂▇▆▆▇██▆█</td></tr><tr><td>valid_loss_epoch</td><td>▃▁▂▁▁▆▆█▅</td></tr><tr><td>valid_loss_step</td><td>▁▄▁▁▁▁▂▂▁▁▂▁▁▁▁▁▂▁▁▁▂▁▂▄▂▂▁▂█▅▂▄▄▄▃▁▁▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>8</td></tr><tr><td>lr-RMSprop</td><td>0.00031</td></tr><tr><td>lr-RMSprop-momentum</td><td>0.98075</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>0.0003</td></tr><tr><td>train_accuracy_epoch</td><td>0.91297</td></tr><tr><td>train_accuracy_step</td><td>0.90625</td></tr><tr><td>train_loss_epoch</td><td>0.28246</td></tr><tr><td>train_loss_step</td><td>0.21516</td></tr><tr><td>trainer/global_step</td><td>27980</td></tr><tr><td>valid_accuracy_epoch</td><td>0.85568</td></tr><tr><td>valid_accuracy_step</td><td>0.66667</td></tr><tr><td>valid_loss_epoch</td><td>0.48263</td></tr><tr><td>valid_loss_step</td><td>0.81116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-6</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/qc0r54yc' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/qc0r54yc</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_072333-qc0r54yc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2fdcrs8d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4471068746231802\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.16413604303027665, 'gamma': 0.673502686885856, 'step_size': 5, 'type': 'constant'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 0.0006039881376290594, 'momentum': 0.9434688529945496, 'type': 'rmsprop', 'weight_decay': 3.532888073102969e-05}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 3\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_085811-2fdcrs8d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2fdcrs8d' target=\"_blank\">resnet-7</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2fdcrs8d' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2fdcrs8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.1 M    Trainable params\n",
      "231 K     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:11<00:00,  6.32it/s, v_num=rs8d]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.978\n",
      "Metric train_accuracy improved. New best score: 0.891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [10:16<00:00,  5.04it/s, v_num=rs8d] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.084 >= min_delta = 0.0. New best score: 0.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [10:17<00:00,  5.03it/s, v_num=rs8d] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.979\n",
      "Metric train_accuracy improved by 0.007 >= min_delta = 0.0. New best score: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [10:09<00:00,  5.10it/s, v_num=rs8d] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.004 >= min_delta = 0.0. New best score: 0.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [10:05<00:00,  5.14it/s, v_num=rs8d] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.006 >= min_delta = 0.0. New best score: 0.985\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3109/3109 [10:06<00:00,  5.13it/s, v_num=rs8d] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.985. Signaling Trainer to stop.\n",
      "Monitored metric train_accuracy did not improve in the last 5 records. Best score: 0.988. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3109/3109 [10:07<00:00,  5.12it/s, v_num=rs8d]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>lr-RMSprop</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████</td></tr><tr><td>lr-RMSprop-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇███▄▆▆▆▆</td></tr><tr><td>train_accuracy_step</td><td>▅█▅█▇▇█▇███▇▇█▇█████▄▇▇▅▇▆▇▇▄▇▇▁█▇▇██▇▆█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▅▃▃▃▃</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▂▁▁▁▁▁▁▁▁▁▁▃▁▂▁▂▂▂▁▁▂▂▂▁▂▃▁▁▃▁▁▂▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▃▄▂▂▂▂▂▂▂▄▂▂▂▂▂▆▃▃▃▃▃▃▃▃▃█▃▃▃▄▄▄</td></tr><tr><td>valid_accuracy_epoch</td><td>▇▄▇▆█▅▂▄▁▄</td></tr><tr><td>valid_accuracy_step</td><td>█▇████▄▇█▇▇██▅▇█████▇██▁▇██▃██▇▇█▅▂▇▇█▆▇</td></tr><tr><td>valid_loss_epoch</td><td>▂▆▁▃▁▃▅▄█▄</td></tr><tr><td>valid_loss_step</td><td>▁▁▁▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▆▁▁▂▄▅▂▃█▁▁█▆▃▆█▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>lr-RMSprop</td><td>0.0006</td></tr><tr><td>lr-RMSprop-momentum</td><td>0.94347</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>4e-05</td></tr><tr><td>train_accuracy_epoch</td><td>0.96398</td></tr><tr><td>train_accuracy_step</td><td>1</td></tr><tr><td>train_loss_epoch</td><td>0.12701</td></tr><tr><td>train_loss_step</td><td>0.01531</td></tr><tr><td>trainer/global_step</td><td>31089</td></tr><tr><td>valid_accuracy_epoch</td><td>0.95201</td></tr><tr><td>valid_accuracy_step</td><td>0.66667</td></tr><tr><td>valid_loss_epoch</td><td>0.16262</td></tr><tr><td>valid_loss_step</td><td>0.79746</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-7</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2fdcrs8d' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/2fdcrs8d</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_085811-2fdcrs8d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 28omy6zd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4499171924989075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.23294841447834624, 'gamma': 0.5058412362747075, 'step_size': 9, 'type': 'exponential'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 1.2747755503276168e-05, 'momentum': 0.8200138678328347, 'type': 'adam', 'weight_decay': 0.000971663713429054}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 2\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_104314-28omy6zd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/28omy6zd' target=\"_blank\">resnet-8</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/28omy6zd' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/28omy6zd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "20.0 M    Trainable params\n",
      "1.3 M     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [07:58<00:00,  6.50it/s, v_num=y6zd]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.990\n",
      "Metric train_accuracy improved. New best score: 0.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [10:00<00:00,  5.18it/s, v_num=y6zd] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.991\n",
      "Metric train_accuracy improved by 0.077 >= min_delta = 0.0. New best score: 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [10:06<00:00,  5.12it/s, v_num=y6zd] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.003 >= min_delta = 0.0. New best score: 0.994\n",
      "Metric train_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [09:53<00:00,  5.24it/s, v_num=y6zd] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.994\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [09:50<00:00,  5.27it/s, v_num=y6zd] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.996\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3109/3109 [09:49<00:00,  5.27it/s, v_num=y6zd] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3109/3109 [09:55<00:00,  5.22it/s, v_num=y6zd] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3109/3109 [09:57<00:00,  5.21it/s, v_num=y6zd] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.996\n",
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3109/3109 [10:11<00:00,  5.08it/s, v_num=y6zd] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.996. Signaling Trainer to stop.\n",
      "Monitored metric train_accuracy did not improve in the last 5 records. Best score: 0.998. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3109/3109 [10:13<00:00,  5.07it/s, v_num=y6zd]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>lr-Adam</td><td>███▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-Adam-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-Adam-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁█████████████</td></tr><tr><td>train_accuracy_step</td><td>██████████████████████▁█████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃█▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆</td></tr><tr><td>valid_accuracy_epoch</td><td>▁▃▆▆██▇██▇▇▇▇▇</td></tr><tr><td>valid_accuracy_step</td><td>██▅██▅▁████▅▅█▅█████▅███████████████████</td></tr><tr><td>valid_loss_epoch</td><td>█▆▃▂▁▂▂▁▁▁▂▂▁▂</td></tr><tr><td>valid_loss_step</td><td>▅▁▁█▅▁▁▁▁▁▁▁▄▁▁▁▁▁▂▁▁▁▁▄▂▁▁▂▂▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>lr-Adam</td><td>0.0</td></tr><tr><td>lr-Adam-momentum</td><td>0.9</td></tr><tr><td>lr-Adam-weight_decay</td><td>0.00097</td></tr><tr><td>train_accuracy_epoch</td><td>0.99792</td></tr><tr><td>train_accuracy_step</td><td>1</td></tr><tr><td>train_loss_epoch</td><td>0.01097</td></tr><tr><td>train_loss_step</td><td>0.00272</td></tr><tr><td>trainer/global_step</td><td>43525</td></tr><tr><td>valid_accuracy_epoch</td><td>0.99517</td></tr><tr><td>valid_accuracy_step</td><td>1</td></tr><tr><td>valid_loss_epoch</td><td>0.01853</td></tr><tr><td>valid_loss_step</td><td>0.00241</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-8</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/28omy6zd' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/28omy6zd</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_104314-28omy6zd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y7cevpwe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4953194345317443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.11834522523218838, 'gamma': 0.5084690760584749, 'step_size': 9, 'type': 'constant'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 0.0006964407436394511, 'momentum': 0.9502625444633452, 'type': 'rmsprop', 'weight_decay': 0.0003556993285146265}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 4\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_130611-y7cevpwe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/y7cevpwe' target=\"_blank\">resnet-9</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/y7cevpwe' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/y7cevpwe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "9.5 K     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:10<00:00,  6.33it/s, v_num=vpwe]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.889\n",
      "Metric train_accuracy improved. New best score: 0.826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [10:01<00:00,  5.17it/s, v_num=vpwe] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.052 >= min_delta = 0.0. New best score: 0.941\n",
      "Metric train_accuracy improved by 0.131 >= min_delta = 0.0. New best score: 0.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [09:59<00:00,  5.19it/s, v_num=vpwe] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.015 >= min_delta = 0.0. New best score: 0.956\n",
      "Metric train_accuracy improved by 0.011 >= min_delta = 0.0. New best score: 0.968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [10:00<00:00,  5.18it/s, v_num=vpwe] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.004 >= min_delta = 0.0. New best score: 0.960\n",
      "Metric train_accuracy improved by 0.005 >= min_delta = 0.0. New best score: 0.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [10:03<00:00,  5.15it/s, v_num=vpwe] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3109/3109 [10:07<00:00,  5.12it/s, v_num=vpwe] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.960. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3109/3109 [10:08<00:00,  5.11it/s, v_num=vpwe]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>lr-RMSprop</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████</td></tr><tr><td>lr-RMSprop-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇███▂▃▄▄</td></tr><tr><td>train_accuracy_step</td><td>▁▃▆▆█▇▇▇██████▇▇███████▇▆▇▇▇▇▇▇▆▇▇▆▅▇▆▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁█▆▆▆</td></tr><tr><td>train_loss_step</td><td>█▆▆▂▃▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▅▃▃▃▃▂▃▃▂▃▂▃▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▇▃▃▃▃█▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>valid_accuracy_epoch</td><td>▆████▂▃▁▂</td></tr><tr><td>valid_accuracy_step</td><td>██▇▇███████████▇█████▅▆█▇▇█▇▇▅██▁█▇▄▇▃█▅</td></tr><tr><td>valid_loss_epoch</td><td>▂▁▁▁▁█▆█▇</td></tr><tr><td>valid_loss_step</td><td>▁▂▁▁▂▁▁▁▃▁▂▁▁▂▂▂▁▁▁▁▃▂▄▁▄█▆▁▆▂▂▅▇▃▄▅▆▇▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>8</td></tr><tr><td>lr-RMSprop</td><td>0.0007</td></tr><tr><td>lr-RMSprop-momentum</td><td>0.95026</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>0.00036</td></tr><tr><td>train_accuracy_epoch</td><td>0.88137</td></tr><tr><td>train_accuracy_step</td><td>0.90625</td></tr><tr><td>train_loss_epoch</td><td>0.39548</td></tr><tr><td>train_loss_step</td><td>0.29504</td></tr><tr><td>trainer/global_step</td><td>27980</td></tr><tr><td>valid_accuracy_epoch</td><td>0.72092</td></tr><tr><td>valid_accuracy_step</td><td>0.66667</td></tr><tr><td>valid_loss_epoch</td><td>1.13018</td></tr><tr><td>valid_loss_step</td><td>0.36956</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-9</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/y7cevpwe' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/y7cevpwe</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_130611-y7cevpwe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6xt4ijpg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1570099819412817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.27866742843560866, 'gamma': 0.31343000554833045, 'step_size': 8, 'type': 'exponential'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 1.5975003529220026e-05, 'momentum': 0.9344751442647392, 'type': 'adam', 'weight_decay': 0.0004974197940479655}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 1\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_144006-6xt4ijpg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/6xt4ijpg' target=\"_blank\">resnet-10</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/6xt4ijpg' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/6xt4ijpg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "13.1 M    Trainable params\n",
      "8.2 M     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [07:56<00:00,  6.52it/s, v_num=ijpg]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.923\n",
      "Metric train_accuracy improved. New best score: 0.872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [09:58<00:00,  5.20it/s, v_num=ijpg] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.015 >= min_delta = 0.0. New best score: 0.938\n",
      "Metric train_accuracy improved by 0.092 >= min_delta = 0.0. New best score: 0.965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [09:47<00:00,  5.29it/s, v_num=ijpg] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.007 >= min_delta = 0.0. New best score: 0.945\n",
      "Metric train_accuracy improved by 0.006 >= min_delta = 0.0. New best score: 0.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [09:58<00:00,  5.20it/s, v_num=ijpg] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [09:54<00:00,  5.23it/s, v_num=ijpg] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.945\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3109/3109 [09:50<00:00,  5.26it/s, v_num=ijpg] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [09:48<00:00,  5.28it/s, v_num=ijpg] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3109/3109 [09:50<00:00,  5.26it/s, v_num=ijpg] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3109/3109 [09:53<00:00,  5.24it/s, v_num=ijpg] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric train_accuracy did not improve in the last 5 records. Best score: 0.973. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3109/3109 [09:54<00:00,  5.23it/s, v_num=ijpg]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>██████▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-Adam-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-Adam-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇█████████</td></tr><tr><td>train_accuracy_step</td><td>▁▅█▄▇▅▇█▅▅█▇███▁▇▄█▇▇██▇███▅█▅▇██▅▅█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▁▂▄▂▂▂▁▄▁▁▁▁▁▃▃▂▂▃▂▄▄▅▃▂▃▁▁▁▁▃▃▂▂▂▂▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▆▂▃▃▃▃▃▃▃▃▃▃█▃▃▃▃▄▄▄</td></tr><tr><td>valid_accuracy_epoch</td><td>▁▆█▆███▇▇█▇</td></tr><tr><td>valid_accuracy_step</td><td>▅▄▅█▇▇▇▅▅▅▇▁██▅▅██▂▅▇██▇▂▂▇██▅█▇▂▄██▅▇▁▅</td></tr><tr><td>valid_loss_epoch</td><td>█▃▁▂▁▁▁▂▂▁▂</td></tr><tr><td>valid_loss_step</td><td>▁▅▄█▁▁▃▂▁▁▂▁▂▂▁▁▁▁▁▁▂▄▂▁▂▂▁▂▁▃▁▁▂▁▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>lr-Adam</td><td>0.0</td></tr><tr><td>lr-Adam-momentum</td><td>0.9</td></tr><tr><td>lr-Adam-weight_decay</td><td>0.0005</td></tr><tr><td>train_accuracy_epoch</td><td>0.97242</td></tr><tr><td>train_accuracy_step</td><td>1</td></tr><tr><td>train_loss_epoch</td><td>0.10124</td></tr><tr><td>train_loss_step</td><td>0.02697</td></tr><tr><td>trainer/global_step</td><td>34198</td></tr><tr><td>valid_accuracy_epoch</td><td>0.94336</td></tr><tr><td>valid_accuracy_step</td><td>1</td></tr><tr><td>valid_loss_epoch</td><td>0.18249</td></tr><tr><td>valid_loss_step</td><td>0.33995</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-10</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/6xt4ijpg' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/6xt4ijpg</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_144006-6xt4ijpg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 112b7a76 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.26943697732669836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.4359303631048743, 'gamma': 0.575424694040573, 'step_size': 4, 'type': 'exponential'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 6.549094227148845e-05, 'momentum': 0.9389648439282108, 'type': 'rmsprop', 'weight_decay': 0.0007416418492389018}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 3\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_163155-112b7a76</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/112b7a76' target=\"_blank\">resnet-11</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/112b7a76' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/112b7a76</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.1 M    Trainable params\n",
      "231 K     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:03<00:00,  6.43it/s, v_num=7a76]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.958\n",
      "Metric train_accuracy improved. New best score: 0.915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [09:59<00:00,  5.19it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.017 >= min_delta = 0.0. New best score: 0.974\n",
      "Metric train_accuracy improved by 0.069 >= min_delta = 0.0. New best score: 0.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [09:59<00:00,  5.18it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.010 >= min_delta = 0.0. New best score: 0.985\n",
      "Metric train_accuracy improved by 0.008 >= min_delta = 0.0. New best score: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [10:03<00:00,  5.15it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.009 >= min_delta = 0.0. New best score: 0.993\n",
      "Metric train_accuracy improved by 0.004 >= min_delta = 0.0. New best score: 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [10:04<00:00,  5.15it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.004 >= min_delta = 0.0. New best score: 0.997\n",
      "Metric train_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3109/3109 [10:11<00:00,  5.09it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.998\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [10:19<00:00,  5.02it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.998\n",
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3109/3109 [10:08<00:00,  5.11it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.999\n",
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3109/3109 [10:02<00:00,  5.16it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.999\n",
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3109/3109 [10:07<00:00,  5.12it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 3109/3109 [10:04<00:00,  5.14it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 3109/3109 [10:04<00:00,  5.14it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3109/3109 [10:02<00:00,  5.16it/s, v_num=7a76] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.999. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3109/3109 [10:04<00:00,  5.15it/s, v_num=7a76]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>lr-RMSprop</td><td>█▅▅▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_epoch</td><td>▁▇▇███████████</td></tr><tr><td>train_accuracy_step</td><td>▁▁▁▆▅████▆███████▆██████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▁▄▁▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▆▇▇▃▃▃█▃▃▃▃▃▄▄▄▄▄▄</td></tr><tr><td>valid_accuracy_epoch</td><td>▁▄▆▇██████████</td></tr><tr><td>valid_accuracy_step</td><td>▇▇▃████████▁▇█▇▇███▇█████▇█████████▇█▅██</td></tr><tr><td>valid_loss_epoch</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss_step</td><td>▃▁▁▁▂▁▁█▂▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>lr-RMSprop</td><td>0.0</td></tr><tr><td>lr-RMSprop-momentum</td><td>0.93896</td></tr><tr><td>lr-RMSprop-weight_decay</td><td>0.00074</td></tr><tr><td>train_accuracy_epoch</td><td>0.99943</td></tr><tr><td>train_accuracy_step</td><td>1</td></tr><tr><td>train_loss_epoch</td><td>0.00692</td></tr><tr><td>train_loss_step</td><td>0.00627</td></tr><tr><td>trainer/global_step</td><td>43525</td></tr><tr><td>valid_accuracy_epoch</td><td>0.99873</td></tr><tr><td>valid_accuracy_step</td><td>1</td></tr><tr><td>valid_loss_epoch</td><td>0.00675</td></tr><tr><td>valid_loss_step</td><td>0.00679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-11</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/112b7a76' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/112b7a76</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250422_163155-112b7a76\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s09vl83k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.17416362442582792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_scheduler: {'factor': 0.4161853336361758, 'gamma': 0.8967782889382125, 'step_size': 6, 'type': 'none'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'learning_rate': 0.0009365408304731924, 'momentum': 0.8745648902743487, 'type': 'adam', 'weight_decay': 0.00033123801004915197}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 2\n",
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./dspro2/efficientnet.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250422_185623-s09vl83k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/s09vl83k' target=\"_blank\">resnet-12</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/sweeps/sauoowd2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/s09vl83k' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/s09vl83k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ASLResNet34        | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | valid_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "20.0 M    Trainable params\n",
      "1.3 M     Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.196    Total estimated model params size (MB)\n",
      "123       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3109/3109 [08:05<00:00,  6.40it/s, v_num=l83k]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved. New best score: 0.965\n",
      "Metric train_accuracy improved. New best score: 0.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3109/3109 [09:56<00:00,  5.21it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.005 >= min_delta = 0.0. New best score: 0.971\n",
      "Metric train_accuracy improved by 0.028 >= min_delta = 0.0. New best score: 0.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3109/3109 [09:55<00:00,  5.22it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.011 >= min_delta = 0.0. New best score: 0.982\n",
      "Metric train_accuracy improved by 0.004 >= min_delta = 0.0. New best score: 0.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3109/3109 [09:58<00:00,  5.19it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3109/3109 [10:00<00:00,  5.18it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3109/3109 [10:01<00:00,  5.17it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [06:30<00:00,  7.96it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3109/3109 [09:57<00:00,  5.20it/s, v_num=l83k]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.006 >= min_delta = 0.0. New best score: 0.988\n",
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3109/3109 [09:58<00:00,  5.20it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3109/3109 [09:51<00:00,  5.26it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.990\n",
      "Metric train_accuracy improved by 0.000 >= min_delta = 0.0. New best score: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3109/3109 [09:52<00:00,  5.25it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_accuracy improved by 0.002 >= min_delta = 0.0. New best score: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3109/3109 [09:55<00:00,  5.22it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_accuracy improved by 0.001 >= min_delta = 0.0. New best score: 0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 3109/3109 [09:58<00:00,  5.20it/s, v_num=l83k] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_accuracy did not improve in the last 5 records. Best score: 0.992. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 3109/3109 [10:00<00:00,  5.17it/s, v_num=l83k]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "uploading data (2h38m)<br>  <strong style=\"color:red\">ERROR</strong> retrying: Post \"https://api.wandb.ai/files/dspro2-silent-speech/silent-speech/s09vl83k/file_stream\": dial tcp 35.186.228.49:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.<br>uploading artifact model-s09vl83k (57.7m)<br>  <strong style=\"color:red\">ERROR</strong> retrying: Post \"https://api.wandb.ai/graphql\": dial tcp 35.186.228.49:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.<br>uploading artifact model-s09vl83k (57.7m)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sweep(sweep_config=sweep_config, count=30, training_procedure=train_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.evaluation import Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = get_asl_resnet_model(get_pretrained_resnet_model(), 0, 0)\n",
    "\n",
    "evaluation = Evaluation(\"resnet-8-eval\", project=PROJECT_NAME, entity=ENTITY_NAME, model_architecture=architecture, artifact=\"dspro2-silent-speech/silent-speech/model-28omy6zd:v2\", datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet-8-eval</strong> at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/ydv9p42g' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/ydv9p42g</a><br> View project at: <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250423_193004-ydv9p42g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\wandb\\run-20250423_194810-t3lxgwbo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/t3lxgwbo' target=\"_blank\">resnet-8-eval</a></strong> to <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dspro2-silent-speech/silent-speech/runs/t3lxgwbo' target=\"_blank\">https://wandb.ai/dspro2-silent-speech/silent-speech/runs/t3lxgwbo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-28omy6zd:v2, 233.66MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    }
   ],
   "source": [
    "model = evaluation.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASLModel(\n",
       "  (model): ASLResNet34(\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Sequential(\n",
       "        (0): Dropout(p=0, inplace=False)\n",
       "        (1): Linear(in_features=512, out_features=28, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (train_accuracy): MulticlassAccuracy()\n",
       "  (valid_accuracy): MulticlassAccuracy()\n",
       "  (test_accuracy): MulticlassAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split folders already exist, skipping distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:817\u001b[39m, in \u001b[36mTrainer._test_impl\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    814\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    815\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    816\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1049\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluating:\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predicting:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:123\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28mself\u001b[39m.on_run_start()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:259\u001b[39m, in \u001b[36m_EvaluationLoop.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    258\u001b[39m data_fetcher.setup(combined_loader)\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# creates the iterator inside the fetcher\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# add the previous `fetched` value to properly track `is_last_batch` with no prefetching\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\fetchers.py:105\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33m_PrefetchDataFetcher\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    107\u001b[39m         \u001b[38;5;66;03m# ignore pre-fetching, it's not necessary\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\fetchers.py:52\u001b[39m, in \u001b[36m_DataFetcher.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33m_DataFetcher\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28mself\u001b[39m.iterator = \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcombined_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\combined_loader.py:351\u001b[39m, in \u001b[36mCombinedLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    350\u001b[39m iterator = \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mself\u001b[39m.flattened, \u001b[38;5;28mself\u001b[39m._limits)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[38;5;28mself\u001b[39m._iterator = iterator\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\combined_loader.py:155\u001b[39m, in \u001b[36m_Sequential.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m._idx = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_current_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\combined_loader.py:173\u001b[39m, in \u001b[36m_Sequential._load_current_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator_idx < \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterables):\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28mself\u001b[39m.iterators = [\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    175\u001b[39m     \u001b[38;5;66;03m# No more iterables to step through, return an empty list\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:491\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:422\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1143\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1144\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1145\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\multiprocessing\\context.py:337\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     94\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m trainer = L.Trainer(accelerator=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:775\u001b[39m, in \u001b[36mTrainer.test\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    774\u001b[39m \u001b[38;5;28mself\u001b[39m.testing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(accelerator=\"auto\")\n",
    "trainer.test(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import lightning as L\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet stats\n",
    "])\n",
    "\n",
    "class PredictDataModule(L.LightningDataModule):\n",
    "    def __init__(self, path: str, batch_size: int = 32, num_workers: int = 0):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.predict_dataset = datasets.ImageFolder(root=r\"C:\\Users\\kybur\\Downloads\", transform=data_transforms, allow_empty=True)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_datamodule = PredictDataModule(path=PATH, batch_size=32, num_workers=20)\n",
    "preds = trainer.predict(model, datamodule=predict_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0, 14,  0,  0,  0, 21,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "for pred in preds:\n",
    "    probabilities = nn.Softmax(dim=-1)(pred)\n",
    "    pred = torch.argmax(probabilities, dim=-1)\n",
    "    # print(probabilities)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Nothing', 'T')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.test_dataset.classes[14],datamodule.test_dataset.classes[21]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
