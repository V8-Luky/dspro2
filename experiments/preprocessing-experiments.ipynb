{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bdcb43a-958d-440d-ac38-2b1b42849790",
   "metadata": {},
   "source": [
    "# Preprocessing Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b270da4-f17d-4d76-9a4c-9c27902b37d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.10-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Downloading kagglehub-0.3.10-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba560e65-53e6-4495-867a-ba858eb27c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32fa77-5722-4302-ac39-01bd99540eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"kapillondhe/american-sign-language\",\n",
    "    \"ayuraj/asl-dataset\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae9ded-9a0f-4c8e-94ed-37ffd8aed475",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    path = kagglehub.dataset_download(dataset)\n",
    "    print(\"Downloaded\", path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bfeda6-6d4a-4599-84fc-e2daeb60dcea",
   "metadata": {},
   "source": [
    "## Problems/Challenges\n",
    "- Dataset only consisting of hands with white skin\n",
    "- Dataset only consisting of white/uniform background\n",
    "- Some signs in ASL are very similar, e.g. they are equal in the relative position of the hand/fingers, but the rotation is slightly differen. Thus some data augmentations like rotation can't be used for all signs.\n",
    "- The dataset(s) only contain images of right handed sign language\n",
    "- To train our model to recognize \"white\" hands in front of white backgrounds we assume we would have enough data, however we don't have enough data for a more generalized model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701ce60-5811-47d1-a084-f9e75c6bcf3d",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "- Data augmentation\n",
    "- Finetuning an existing image recoginition model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b2474-35a9-4e80-afae-61a0b937c7d2",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "#### Biased Skin Color\n",
    "**Augmentation**\n",
    "\n",
    "We could generate new images by transforming the HSV/RGB values of the hands in our existing dataset to HSV/RGB values of hands with different skin color.\n",
    "\n",
    "**Histogram Matching**\n",
    "\n",
    "Could use the color distribution of different skin tones and match our dataset with it.\n",
    "\n",
    "#### Biased Background\n",
    "**Substitute the Background**\n",
    "\n",
    "Could apply a HSV filter to our images to cut out the hand and replace the background with random values or random background images from the internet.\n",
    "\n",
    "**Diverse Filters**\n",
    "\n",
    "Could apply blur and other filters to make the learning less susceptible to noise.\n",
    "\n",
    "#### Combined\n",
    "**Gray Scale Images**\n",
    "\n",
    "Could we work with gray scaled images to reduce the dependency on the background as well as on the skin color.\n",
    "\n",
    "#### Similar Signs\n",
    "We can't solve the problem that some signs are similar, but we can try to make the distinction between the similar signs as clear as possible by not \"augmenting\" one sign into the other. We have to pay attention for the following signs:\n",
    "\n",
    "- I vs. J: J is the same sign as I, but with a slight motion. We are bound to run into a problem here. But we can define I as being an upright pinky finger and J being the one that is in a range of other positions.\n",
    "\n",
    "The other signs are distinguishable from each other, however M, N, S, T and A are very similary and only show tiny differences. This might pose a problem for the model.\n",
    "\n",
    "#### Right Handed Bias\n",
    "The signs for right handed people and left handed people are equal if flipped. Hence we can cover left handed sign language by flipping our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd76a9-c404-4096-9cac-310ef5a5c23f",
   "metadata": {},
   "source": [
    "### Model Solutions\n",
    "These solutions don't replace the above but only extend them.\n",
    "\n",
    "**Finetune existing model**\n",
    "\n",
    "Could finetune an existing model like ResNet or EfficientNet with our own, augmented dataset. This could for one improve performance and for another get rid of some of the biases we already have. We have to make sure to still have our own models (and a baseline model) as a control group.\n",
    "\n",
    "How to finetune ResNet: https://medium.com/@engr.akhtar.awan/how-to-fine-tune-the-resnet-50-model-on-your-target-dataset-using-pytorch-187abdb9beeb\n",
    "\n",
    "How to finetune EfficientNet: https://www.restack.io/p/fine-tuning-answer-efficientnet-pytorch-cat-ai\n",
    "\n",
    "Other models that already work with pose detection as opposed to object detection:\n",
    "\n",
    "MediaPipe: https://pypi.org/project/mediapipe/\n",
    "OpenPose: https://cmu-perceptual-computing-lab.github.io/openpose/web/html/doc/md_doc_03_python_api.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d346ad-e42c-4903-a993-e0afe25526c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
