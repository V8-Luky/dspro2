{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8bbdd2b-4af9-460e-8c17-b0bd2286253c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.12/site-packages (from mediapipe) (25.1.0)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting jax (from mediapipe)\n",
      "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Downloading jaxlib-0.6.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (from mediapipe) (3.10.1)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Using cached protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.12/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting opt_einsum (from jax->mediapipe)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /opt/conda/lib/python3.12/site-packages (from jax->mediapipe) (1.15.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Using cached mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading jax-0.6.1-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.6.1-cp312-cp312-manylinux2014_x86_64.whl (89.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: sentencepiece, flatbuffers, protobuf, opt_einsum, numpy, absl-py, sounddevice, opencv-contrib-python, ml_dtypes, jaxlib, jax, mediapipe\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.28.3\n",
      "    Uninstalling protobuf-5.28.3:\n",
      "      Successfully uninstalled protobuf-5.28.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed absl-py-2.2.2 flatbuffers-25.2.10 jax-0.6.1 jaxlib-0.6.1 mediapipe-0.10.21 ml_dtypes-0.5.1 numpy-1.26.4 opencv-contrib-python-4.11.0.86 opt_einsum-3.4.0 protobuf-4.25.7 sentencepiece-0.2.0 sounddevice-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d71ee-09e7-410d-bbca-537448de66b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1747990059.855955    7832 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747990059.875990    7832 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747990060.004098    7810 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train/A] Processed 2000/3565 images...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pathlib\n",
    "\n",
    "# Paths\n",
    "asl_dataset_path = '/exchange/dspro2/silent-speech/ASL_Pictures_Dataset'\n",
    "output_path = '/exchange/dspro2/silent-speech/ASL_Landmarks_Dataset'\n",
    "\n",
    "# Ensure output folder exists and has the right structure\n",
    "subsets = ['Train', 'Validation', 'Test']\n",
    "for subset in subsets:\n",
    "    (pathlib.Path(output_path) / subset).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "print(\"Started processing\")\n",
    "\n",
    "# Process all images in the split dataset\n",
    "with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7) as hands:\n",
    "    for subset in subsets:\n",
    "        subset_path = pathlib.Path(asl_dataset_path) / subset\n",
    "        for label_folder in subset_path.iterdir():\n",
    "            if not label_folder.is_dir():\n",
    "                continue\n",
    "\n",
    "            label = label_folder.name\n",
    "            image_paths = list(label_folder.glob(\"*.jpg\")) + list(label_folder.glob(\"*.jpeg\")) + list(label_folder.glob(\"*.png\"))\n",
    "            total_images = len(image_paths)\n",
    "            processed_images = 0\n",
    "\n",
    "            X, y = [], []\n",
    "\n",
    "            for idx, image_path in enumerate(image_paths):\n",
    "                processed_images += 1\n",
    "                if processed_images % 2000 == 0 or processed_images == total_images:\n",
    "                    print(f\"[{subset}/{label}] Processed {processed_images}/{total_images} images...\")\n",
    "\n",
    "                image = cv2.imread(str(image_path))\n",
    "                if image is None:\n",
    "                    continue\n",
    "\n",
    "                # Flip every second image to simulate left-handedness\n",
    "                if idx % 2 == 0:\n",
    "                    image = cv2.flip(image, 1)\n",
    "\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                results = hands.process(image_rgb)\n",
    "\n",
    "                if results.multi_hand_landmarks:\n",
    "                    landmarks = results.multi_hand_landmarks[0].landmark\n",
    "                    coordinates = np.array([(lm.x, lm.y, lm.z) for lm in landmarks]).flatten()\n",
    "                    X.append(coordinates)\n",
    "                    y.append(label)\n",
    "\n",
    "            # Save per label per subset\n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            out_folder = pathlib.Path(output_path) / subset\n",
    "            np.save(out_folder / f\"X_{label}.npy\", X)\n",
    "            np.save(out_folder / f\"y_{label}.npy\", y)\n",
    "\n",
    "print(f\"✅ Landmark conversion complete. Data saved in {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
