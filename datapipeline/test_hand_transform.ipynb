{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4bf7a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557ecef-24b5-4f27-9300-183f188f8929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hand_transform import *\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as visionmodels\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from datapipeline.asl_transforms import RandomBackgroundNoiseTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a244ef-101c-4d97-a499-7627985dae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "img_size = 224\n",
    "\n",
    "# See https://pytorch.org/vision/master/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py\n",
    "# for more examples of transforms\n",
    "\n",
    "# Open Idea: Grayscale for anti bias\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.3, hue=0.3), # Idea: ColorJitter for anti bias\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet stats\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95422444-4a12-4198-b530-3d8bf49ec500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackgroundNoiseTransform(nn.Module):\n",
    "    def __init__(self, brightness=0.75, contrast=0.3, saturation=.75, hue=0.4):\n",
    "        super().__init__()\n",
    "        self.color_jitter = transforms.ColorJitter(brightness=brightness, contrast=contrast, saturation=saturation, hue=hue)\n",
    "\n",
    "    def get_hand_filter(self, img):\n",
    "        image_hsv = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n",
    "       \n",
    "        hsv_min = [np.array([0, 0, 100])]\n",
    "        hsv_max = [np.array([180, 60,255])]\n",
    "        \n",
    "        hsv_min, hsv_max = np.array(hsv_min), np.array(hsv_max)\n",
    "           \n",
    "        background_image_hsv = sum([cv.inRange(image_hsv, lower, upper) for lower, upper in zip(hsv_min, hsv_max)])\n",
    "        \n",
    "        binary = np.copy(background_image_hsv)\n",
    "        binary = cv.bitwise_not(binary)\n",
    "        \n",
    "        binary = cv.GaussianBlur(binary, (3,3), 3)\n",
    "        return binary\n",
    "\n",
    "    def noise(self, mask, img):\n",
    "        noise = np.random.uniform(0, 255, size=img.shape).astype(np.uint8)\n",
    "        noise[mask == 255] = img[mask == 255]\n",
    "        return noise  \n",
    "    \n",
    "    def __call__(self, img):\n",
    "        color_jittered = np.array(self.color_jitter(img))\n",
    "        \n",
    "        img_np = np.array(img)\n",
    "        mask = self.get_hand_filter(img_np)\n",
    "        \n",
    "        noised = self.noise(mask, color_jittered)\n",
    "        noised_with_gaussian = cv.GaussianBlur(noised, (3,3), 1.5)\n",
    "\n",
    "        return Image.fromarray(noised_with_gaussian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20667e3-6e03-4313-9bb0-0aef941a4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transforms.Compose(transforms=(\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    RandomNoiseBackgroundTransform(),\n",
    "    #transforms.ColorJitter(brightness=1.0, contrast=0.0, saturation=1.0, hue=0.5),\n",
    "    #transforms.Grayscale(),\n",
    "    #transforms.GaussianBlur(kernel_size=(3,3),sigma=3)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7f4b846-738d-443d-83b0-e59e7fb86f2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\exchange\\\\dspro2\\\\silent-speech\\\\ASL_Pictures_Dataset\\\\Train\\\\D\\\\10.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# orig_img = Image.open(Path(\"/home/jovyan/Test-Hands/A\") / 'A_1.jpeg')\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m orig_img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/exchange/dspro2/silent-speech/ASL_Pictures_Dataset/Train/D\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m10.jpg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kybur\\Repos\\HSLU\\dspro2\\.venv\\Lib\\site-packages\\PIL\\Image.py:3465\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3462\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3465\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3466\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '\\\\exchange\\\\dspro2\\\\silent-speech\\\\ASL_Pictures_Dataset\\\\Train\\\\D\\\\10.jpg'"
     ]
    }
   ],
   "source": [
    "# orig_img = Image.open(Path(\"/home/jovyan/Test-Hands/A\") / 'A_1.jpeg')\n",
    "orig_img = Image.open(Path(r\"/exchange/dspro2/silent-speech/ASL_Pictures_Dataset/Train/D\") / '10.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ebddb42-3583-4551-8981-8649cc369bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orig_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plt.imshow(t(\u001b[43morig_img\u001b[49m))\n",
      "\u001b[31mNameError\u001b[39m: name 'orig_img' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(t(orig_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713cdb4-c038-49a0-a6a5-f6bc94e32276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a55fc4-bfb9-4c8b-bbe6-f34c817dd170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
